# Data Formulator 使用指南

> 本文基于官方 README 与本地源码整理，重点介绍 **如何实际使用 Data Formulator** 进行数据探索与可视化。

---

## 1. 工具概览

**Data Formulator** 是 Microsoft Research 推出的一个交互式数据分析与可视化工具：

- 通过 **AI agent** 帮你完成数据转换、图表推荐和报告生成；
- 支持 **从多种来源加载数据**：结构化文件、截图、文本、数据库等；
- 允许你在 **拖拽 UI** 与 **自然语言指令** 之间自由切换；
- 使用 "数据线程（Data Threads）" 追踪探索路径，支持回溯、分支探索；
- 可以一键生成基于当前探索过程的 **图文报告**。

适用场景：

- 做探索性数据分析（EDA）；
- 需要快速尝试多种图表、视角和数据变换；
- 希望借助大模型减少写 SQL / Python 的负担，但仍保留可控性和可验证性。

---

## 2. 启动方式概览

Data Formulator 典型的启动方式有两类：

- **快速体验（通过 pip 安装官方包）**  
  适合只想本机体验功能、不改源码的场景：
  ```bash
  pip install data_formulator
  python -m data_formulator
  ```
  运行后浏览器会自动打开：<http://localhost:5000>

- **本地开发模式（克隆本仓库）**  
  适合你当前这种：从 GitHub 克隆源码、本地开发和二次定制的场景。  
  **详细的依赖安装、本地 llama.cpp / Ollama 配置、`yarn build` 与 `./local_server.sh` 启动步骤，请完全参考项目根目录的《安装步骤.md》。**

只要你已经能在浏览器成功访问：<http://localhost:5000>，就可以从本指南第 3 节开始，专注于“如何用它做分析”。

---

## 3. 界面与核心概念

界面细节可能会随版本略有变化，但整体思想不变。典型界面主要包含：

- **数据区域**：用于选择、上传或预览当前数据集；
- **图表区域 / 画布**：展示当前图表和交互控件；
- **编码/配置区**：配置 X/Y 轴、颜色、大小、过滤等可视化编码；
- **对话 / 指令区域**：输入自然语言需求，例如“画出按地区汇总的销售额柱状图”；
- **模型与代理设置**：配置使用哪个大模型（OpenAI、本地 llama.cpp、Ollama 等），并将模型分配给不同任务；
- **数据线程（Data Threads）/ 历史面板**：记录每一步数据转换、图表和对话，可以回溯或分支。

核心概念：

- **数据表（Tables）**：你导入或连接得到的数据；
- **派生字段 / 概念（Derived Concepts）**：通过 AI 生成的新字段，例如“利润率”“同比增长”；
- **探索线程（Exploration Threads）**：一次从数据到图表、再到后续修改的完整链路；
- **Agent 模式**：给出探索目标/问题，由 AI 规划和执行多步分析。

---

## 4. 数据加载方式

Data Formulator 支持多种数据来源：

1. **上传本地文件**
   
   - 支持常见格式：`csv`、`tsv`、`xlsx` 等；
   - 典型流程：在界面中找到“加载 / 导入数据”的入口，选择本地文件上传；
   - 上传后，可以在数据预览中检查字段类型、行数等。

2. **从截图 / 文本中提取表格数据**

   - 你可以上传一张表格截图，或一块带有表格结构的纯文本；
   - AI 会尝试自动解析出结构化表格，供后续可视化使用；
   - 适合处理报告截图、PDF 表格等“半结构化”数据。

3. **从网站或非结构化文本抓取数据**

   - 提供一个网页 URL 或一段包含数据的描述性文字；
   - 系统会尝试解析出表格形式的数据；

4. **连接外部数据库 / 数据湖**

   - Data Formulator 提供外部数据加载器（见 `py-src/data_formulator/data_loader`）：
     - MySQL / PostgreSQL / MSSQL；
     - Azure Data Explorer (Kusto)；
     - S3 / Azure Blob （json / parquet / csv 等）。
   - 一般流程是：
     - 在相应的配置文件中填好连接配置（如主机、端口、数据库名、认证信息等）；
     - 在前端选择对应数据源，从数据列表中选表或查询结果。

5. **大数据场景与 DuckDB 集成**

   - 对于较大的本地文件，可以通过 DuckDB 建立本地数据库；
   - Data Formulator 只在绘图时按需拉取子集，提高交互速度。

> **建议**：首次使用时可以先使用项目内置的示例数据集（在菜单或示例数据区中），熟悉整体交互流程。

---

## 5. 与 AI 的几种协作模式

官方文档中将探索模式按“控制程度”划分为多个 Level，你可以根据需求选择不同方式与 AI 协作。

### 5.1 Level 1：完全手动控制（拖拽 UI）

- 适合你已经对数据结构比较熟悉，或有明确的图表设计；
- 典型操作：
  - 从字段列表中拖拽字段到 X 轴、Y 轴、颜色、大小等位置；
  - 设置聚合方式（sum、avg、count 等）、排序、筛选条件；
  - 调整图表类型（柱状图、折线图、散点图等）。

### 5.2 Level 2：NL + UI 混合（自然语言描述图表设计）

- 当你希望由 AI 帮忙做一些数据转换或复杂图表设计时：
  - 在编码区指定部分字段；
  - 在文本框里描述你想看到的图表，例如：
    > “按地区汇总 2024 年的总销售额，画成堆叠柱状图，并按销售额从高到低排序。”
  - 系统会自动生成需要的数据转换代码（Python / SQL）和图表配置。

### 5.3 Level 3：图表推荐与探索建议

- 你可以直接用自然语言描述数据和问题，例如：
  > “这份电商订单数据中，帮我找出最重要的影响复购率的因素。”

- Agent 会：
  - 先理解数据结构；
  - 自动提出若干图表建议，给出不同的分析视角；
  - 你可以从推荐图表中选择、修改或继续追问。

### 5.4 Level 4：Agent 模式，多轮自动探索

- 输入一个较高层次的目标，例如：
  > “分析 2023 年不同渠道的用户增长情况，并总结关键洞察。”

- Agent 会：
  - 规划多步分析计划；
  - 自动创建多个图表和数据转换步骤；
  - 在数据线程中记录每一轮结果，你可以随时打断、修改或追加指令。

### 5.5 实际使用建议

- 复杂问题可以从 Level 3/4 入手，让 agent 给你初始方案；
- 然后回到 Level 1/2，通过拖拽和微调指令细化图表和数据处理；
- 避免完全依赖自动结果，建议始终结合图表和数据表检查 AI 输出是否合理。

---

## 6. 模型配置与管理

Data Formulator 支持通过 LiteLLM 调用多种模型提供商，包括：OpenAI、Azure、Ollama、本地 OpenAI 兼容服务（如 llama.cpp）、Anthropic 等。

### 6.1 后端环境变量 / 配置文件

- 模型配置主要来自项目根目录下的 `api-keys.env`（可以从 `api-keys.env.template` 复制得到）。
- 每个 provider 一般有如下字段：
  - `*_ENABLED`：是否启用该 provider（`true` / `false`）；
  - `*_API_KEY`：API Key（如果不需要鉴权可以填占位值）；
  - `*_API_BASE`：自定义接口地址，例如本地 llama.cpp 的 `http://localhost:8080/v1`；
  - `*_MODELS`：可用模型名称列表，逗号分隔，如 `gpt-oss-20b`；
  - 某些 provider 还需要 `*_API_VERSION`。

你可以通过 `安装步骤.md` 中的示例，配置本地 llama.cpp / Ollama 或云端模型。

### 6.2 前端模型选择与测试

在应用右上角通常可以打开“模型配置对话框”（Model Selection）：

- 列表中会显示当前所有已配置的模型项（每一行包含 provider、model、api_base、状态等）；
- 你可以：
  - 为不同任务槽位（如生成、提示等）选择不同模型；
  - 为新 provider 填写 endpoint、model、api_key、api_base、api_version；
  - 点击“Test”来测试某个模型是否可用；
  - 只有状态为 `Ready` 的模型，才适合用于正式分析。

> 如果看到类似 “Error testing ... Connection error” 的日志：
>
> - 检查对应的 `*_ENABLED` 是否需要关闭；
> - 检查 `API_BASE`、`API_KEY`、`MODELS` 是否与你的服务实际配置一致；
> - 对于本地 llama.cpp，要确保 `llama-server` 正在运行且端口与路径匹配。

---

## 7. 典型使用流程示例

下面给出一个从零开始的完整示例，帮助你理解 Data Formulator 的日常用法。

### 场景 1：分析电商订单数据

1. **确认应用已启动**
   - 按《安装步骤.md》或上文“启动方式概览”中的任一方式启动 Data Formulator；
   - 能在浏览器访问 <http://localhost:5000> 即表示就绪。

2. **加载数据**
   - 选择上传一个包含订单数据的 `orders.csv`；
   - 确认字段包括：订单时间、用户 ID、商品类目、金额、渠道等。

3. **简单浏览数据**
   - 在表格预览中滚动查看；
   - 可以让 AI 帮你总结数据大致结构：
     - 例如在对话框中输入：“这份数据里有哪些字段？各自代表什么？”

4. **构建基础图表（Level 1）**
   - 手动拖拽：
     - X 轴：日期（按月）；
     - Y 轴：订单金额（sum）；
     - 生成一个基础销售额趋势图。

5. **使用自然语言细化图表（Level 2）**
   - 在同一个图表基础上，输入：
     > “只看 2023 年的数据，并按渠道拆分为堆叠柱状图。”
   - Agent 会自动过滤年份、分组并更新图表。

6. **获取推荐分析（Level 3）**
   - 在探索面板中描述：
     > “帮我找出高价值用户（消费金额 top 10%）的典型行为特征。”
   - Agent 可能会建议：
     - 用户分层（RFM 或按消费金额分组）；
     - 生成按类目、时间、渠道的对比图表。

7. **使用 Agent 模式做多轮探索（Level 4）**
   - 给出更高层目标：
     > “分析不同渠道在 2023 年的用户增长和留存情况，并给出关键结论。”
   - Agent 会自动：
     - 构建多个中间图表；
     - 在数据线程中记录每一步结果；
     - 你可以在任意一步：
       - 修改图表；
       - 让 agent 继续 follow-up；
       - 或从当前状态分叉一条新线程。

8. **生成报告**
   - 在报告构建界面中：
     - 选择若干想要展示的图表；
     - 指定报告风格（如“博客风格说明文”）；
     - 让 AI 生成一份自带文字说明的分析报告；
     - 可以复制、导出或截图保存。

### 场景 2：从截图 / 文本提取表格并快速出图

适用：手里只有报告截图、PDF 表格或一段“看起来像表格”的文本，希望快速变成可分析的数据和图表。

1. **上传截图或文本**  
   - 在数据面板中找到“从图片 / 截图 / 文本提取数据”的入口（具体文案可能略有差异）；
   - 选择一张包含表格的截图，或粘贴一段带有表格结构的文本；
   - 提交后，等待 AI 将其解析为结构化表格。

2. **检查并修正解析结果**  
   - 在数据预览区域查看生成的表格：字段名、行数、数值是否合理；
   - 如有明显错误，可手动修改字段名或删除错误行；
   - 也可以在对话区域输入：
     > “帮我检查一下这张表是否有解析错误或异常值，并给出建议。”

3. **基于解析结果快速出图**  
   - 在图表区域选择这张解析后的表作为当前数据源；
   - 在文本框中描述你想看的图表，例如：
     > “按地区和产品类别统计总销售额，画成分组柱状图，并按销售额从高到低排序。”
   - 执行后，系统会自动进行必要的数据聚合与编码配置，生成初始图表；
   - 你可以继续通过拖拽字段或追加指令微调图表样式和过滤条件。

### 场景 3：用 Agent 模式做“问题驱动”的探索

适用：你关心的是一个问题或目标，而不是先想好具体画什么图。

示例问题：

- “哪些因素最能解释用户转化率的差异？”
- “帮我总结 2023 年不同渠道的用户增长与留存情况，并给出关键结论。”

操作步骤：

1. **准备好数据**  
   - 可以是上传的订单 / 用户行为数据，也可以是从数据库 / DuckDB 中加载的表；
   - 确认在数据面板中已经选定当前要分析的数据表。

2. **打开 Agent / 探索面板**  
   - 在界面中找到与“Agent / 探索 / 问题驱动分析”相关的入口；
   - 在输入框中直接描述你的分析目标，例如：
     > “分析 2023 年不同渠道新用户的增长趋势，以及留存情况。”

3. **查看 Agent 给出的计划和图表**  
   - Agent 通常会：
     - 给出一个多步分析思路（如先看整体趋势，再看渠道拆分，再看留存）；
     - 自动生成若干图表和中间数据转换结果；
   - 这些图表和步骤会以“探索线程”的形式记录在侧边面板中。

4. **在探索线程中迭代**  
   - 对某一步结果不满意时，可以：
     - 在对应图表旁边输入 follow-up 指令，例如：
       > “改成只看 2023 年 Q4，并按地区拆分。”  
       > “把横轴改成用户注册月，纵轴用 30 天留存率。”
     - 或者手动调整图表编码（字段、聚合、过滤），再让 Agent 继续基于新的结果往下分析；
   - 也可以在任意节点“分叉”出一条新探索路径，用不同角度继续深入。

5. **从探索到报告**  
   - 当你觉得探索结果足够丰富时，可以像场景 1 那样进入报告构建界面；
   - 选择由 Agent 生成的关键图表，要求系统：
     > “根据这些图表，写一份面向业务同事的分析报告，突出渠道差异和策略建议。”
   - 根据生成的文字说明进行审阅和必要修改。

---

## 8. 常见问题与排查建议

### 8.1 打开 <http://localhost:5000> 报 500 / 找不到 index.html

典型原因：前端静态资源未正确构建（例如缺少 `py-src/data_formulator/dist/index.html`）。

解决思路：

- 请参考《安装步骤.md》中“运行应用”和“问题排查”小节；
- 一般需要：确认前端依赖已安装、执行过一次前端构建、然后重新启动后端服务。

### 8.2 日志中有大量 "Error testing ... model ..." 信息

- 检查 `api-keys.env` 中是否把不用的 provider 也设成了 `*_ENABLED=true`：
  - 不用的统一改成 `false`；
- 对正在使用的 provider：
  - 确认 `API_BASE`、`API_KEY`、`MODELS` 正确；
  - 对本地 llama.cpp，确认 `llama-server` 正在运行、端口和路径无误。

### 8.3 本地 llama.cpp 能用 curl 调通，但前端仍显示模型不可用

- 确认：
  - `OPENAI_ENABLED=true`；
  - `OPENAI_API_BASE` 与 curl 中一致（如 `http://localhost:8080/v1`）；
  - `OPENAI_MODELS` 使用的模型名与 curl 请求里的 `"model"` 一致；
- 在模型配置对话框中重新“Test”该模型，并查看日志中是否还有 Connection error。

### 8.4 数据很大时前端响应慢

- 尽量使用 DuckDB / 外部数据库方式，让 Data Formulator 只按需取子集；
- 减少单次图表中展示的点数（聚合或取样）。

---

## 9. 进一步阅读

- 官方 GitHub 仓库（英文）：
  - <https://github.com/microsoft/data-formulator>
- 本项目内文档：
  - `README.md`：整体介绍与英文使用说明；
  - `DEVELOPMENT.md`：开发者指南、构建与打包说明；
  - `安装步骤.md`：本地环境搭建与本地模型配置（包括 llama.cpp）；
  - `py-src/data_formulator/data_loader`：外部数据加载器相关说明。

---

如果你希望，我可以基于你的实际使用习惯，进一步在本指南里增加“公司/项目内推荐工作流示例”，比如固定的数据源、常用图表模板等。
